# linkedIn_scrape_datasets
Clean Data
The steps are simple: collect, clean, and analyze data.
Data
We chose LinkedIn as the jobs listing platform to scrape. To do so, we wrote a python script to go through LinkedIn and collected all the necessary data. Locations were chosen: Canada and USA.
Features
    ● title: Job title
    ● company: Name of the company
    ● description: description of the job and company
    ● Location: The location where the employee will be working from
    ● salary: Salary for the job. It may be yearly or hourly. In most cases, it is a range
    from min to max
    ● location: Where the company with the opening role is located
    ● criteria: Job requirements like experience, employment type, etc
    ● posted_date: The date the job was posted
    ● link: The URL to the job
Analyze Data
We continue python's libraries.
Stack
● Pandas
● Seaborn
● Matplotlib
● Numpy
● Excel
● Jupyter Notebook
